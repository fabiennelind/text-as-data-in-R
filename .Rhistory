negative <- negative %>% as_tibble() %>%
mutate(polarity = "negative")
positive <- positive %>% as_tibble() %>%
mutate(polarity = "positive")
bind_rows(positive, negative)
bind_rows(positive, negative) %>%
write_csv("~/Desktop/tad_course/rotten_tomatoes.csv")
mu_madison <- fed %>%
filter(author == "MADISON") %>%
select(man, by, upon) %>%
colSums()
mu_hamilton <- fed %>%
filter(author == "HAMILTON") %>%
select(man, by, upon) %>%
colSums()
mu_jay <- fed %>%
filter(author == "JAY") %>%
select(man, by, upon) %>%
colSums()
mu_madison
mu_hamilton
mu_jay
mu_hat_hamilton
mu_hat_madison
mu_hat_jay
mu_disputed
p_disputed_madison
getwd()
setwd("~/Desktop/tad_course/")
inspect(dtm)
dtm
texts
length(texts)
str_split(text)
str_split(texts)
str_split(texts, " ")
str_split(texts, " ") %>% do.call
str_split(texts, " ") %>% do.call()
str_split(texts, " ") %>% unlist()
str_split(texts, " ") %>% unlist() %>% unique()
dtm <- DocumentTermMatrix(texts,
control = list(stopwords = FALSE,
removePunctuation = FALSE)
)
inspect(dtm)
length(texts)
str_split(texts, " ") %>% unlist() %>% unique()
n <- length(texts)
unique_terms <- str_split(texts, " ") %>% unlist() %>% unique()
k <- length(unique_terms)
x <- matrix(n, k, NA)
x <- matrix(nrows = n, ncols = k, NA)
?matrix
x <- matrix(nrow = n, ncol = k, NA)
X
x
all_words <- str_split(texts, " ") %>% unlist()
all_words
all_words
current_text <- str_split(texts[i], " ")
x <- matrix(nrow = n, ncol = k, 0)
x
i = 1
current_text <- str_split(texts[i], " ")
current_text
current_text <- str_split(texts[i], " ")[[1]]
current_text
str_to_lower(texts)
texts <- str_to_lower(texts)
current_text
current_text
"John" %in% current_text
texts <- str_to_lower(texts)
n <- length(texts)
all_words <- str_split(texts, " ") %>% unlist()
unique_terms <- str_split(texts, " ") %>% unlist() %>% unique()
k <- length(unique_terms)
x <- matrix(nrow = n, ncol = k, 0)
for (i in nrow(x)) {
current_text <- str_split(texts[i], " ")[[1]]
for (j in ncol(x)) {
for (y in 1:length(current_text)) {
if (current_text[y] %in% unique_terms[j]) {
x[i, j] = x[i, j] + 1
}
}
}
}
x
current_text
j
unique_terms[j]
for (y in 1:length(current_text)) {
current_text[y] %in% unique_terms[j]
}
for (y in 1:length(current_text)) {
print(current_text[y] %in% unique_terms[j])
}
current_text
unique_terms
i
y
i = 1
for (y in 1:length(current_text)) {
print(current_text[y] %in% unique_terms[j])
}
current_text <- str_split(texts[i], " ")[[1]]
for (y in 1:length(current_text)) {
print(current_text[y] %in% unique_terms[j])
}
i = 2
j = 2
unique_terms
for (y in 1:length(current_text)) {
print(current_text[y] %in% unique_terms[j])
}
current_text
unique_terms
texts <- str_to_lower(texts)
n <- length(texts)
all_words <- str_split(texts, " ") %>% unlist()
unique_terms <- str_split(texts, " ") %>% unlist() %>% unique()
k <- length(unique_terms)
x <- matrix(nrow = n, ncol = k, 0)
for (i in nrow(x)) {
current_text <- str_split(texts[i], " ")[[1]]
for (j in ncol(x)) {
for (y in 1:length(current_text)) {
if (current_text[y] %in% unique_terms[j]) {
x[i, j] = x[i, j] + 1
}
}
}
}
x
all_words <- str_split(texts, " ") %>% unlist()
unique_terms <- str_split(texts, " ") %>% unlist() %>% unique()
k <- length(unique_terms)
x <- matrix(nrow = n, ncol = k, 0)
for (i in nrow(x)) {
current_text <- str_split(texts[i], " ")[[1]]
for (j in ncol(x)) {
for (y in 1:length(current_text)) {
if (current_text[y] == unique_terms[j]) {
x[i, j] = x[i, j] + 1
}
}
}
}
x
current_text[y]
unique_terms[j]
current_text[y] == unique_terms[j]
i = 1
j = 1
current_text <- str_split(texts[i], " ")[[1]]
x
x <- matrix(nrow = n, ncol = k, 0)
for (y in 1:length(current_text)) {
if (current_text[y] == unique_terms[j]) {
x[i, j] = x[i, j] + 1
}
}
x
1:length(current_text)
current_text
y
unique_terms[j]
x
for (y in 1:length(current_text)) {
if (current_text[y] %in% unique_terms[j]) {
x[i, j] = x[i, j] + 1
}
}
x
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
x[i, j] = x[i, j] + 1
}
}
x
texts <- str_to_lower(texts)
n <- length(texts)
all_words <- str_split(texts, " ") %>% unlist()
unique_terms <- str_split(texts, " ") %>% unlist() %>% unique()
k <- length(unique_terms)
x <- matrix(nrow = n, ncol = k, 0)
for (i in nrow(x)) {
current_text <- str_split(texts[i], " ")[[1]]
for (j in ncol(x)) {
for (y in 1:length(current_text)) {
if (current_text[y] == unique_terms[j]) {
x[i, j] = x[i, j] + 1
}
}
}
}
x
texts <- str_to_lower(texts)
n <- length(texts)
all_words <- str_split(texts, " ") %>% unlist()
unique_terms <- str_split(texts, " ") %>% unlist() %>% unique()
k <- length(unique_terms)
x <- matrix(nrow = n, ncol = k, 0)
for (i in nrow(x)) {
current_text <- str_split(texts[i], " ")[[1]]
for (j in ncol(x)) {
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
x[i, j] = x[i, j] + 1
}
}
}
}
x
x <- matrix(nrow = n, ncol = k, 0)
x
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
x[i, j] = x[i, j] + 1
}
}
x
current_text
i = 1
j = 1
current_text <- str_split(texts[i], " ")[[1]]
current_text
unique_terms[j]
y
y = 1
unique_terms[j]
unique_terms[j] %in% current_text[y]
j = 2
unique_terms[j] %in% current_text[y]
unique_terms[3] %in% current_text[y]
unique_terms[3]
unique_terms[j]
j
j = 1
unique_terms[j]
current_text[y]
current_text
unique_terms[j]
str_count(current_text, unique_terms[j])
str_count(unique_terms[j], current_text)
dtm
as.matrix(dtm) %>% colSums() %>% sum()
inspect(dtm)
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
x[i, j] = x[i, j] + 1
}
}
x
x
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
x[i, j] = x[i, j] + 1
}
}
x
x <- matrix(nrow = n, ncol = k, 0)
i = 2
j = 2
x
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
x[i, j] = x[i, j] + 1
}
}
x
x
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
x[i, j] = x[i, j] + 1
}
}
x
j
j = 3
x
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
x[i, j] = x[i, j] + 1
}
}
x
all_words <- str_split(texts, " ") %>% unlist()
unique_terms <- str_split(texts, " ") %>% unlist() %>% unique()
k <- length(unique_terms)
x <- matrix(nrow = n, ncol = k, 0)
for (i in nrow(x)) {
current_text <- str_split(texts[i], " ")[[1]]
for (j in ncol(x)) {
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
x[i, j] = 1
}
}
}
}
x
all_words <- str_split(texts, " ") %>% unlist()
unique_terms <- str_split(texts, " ") %>% unlist() %>% unique()
k <- length(unique_terms)
x <- matrix(nrow = n, ncol = k, 0)
for (i in nrow(x)) {
current_text <- str_split(texts[i], " ")[[1]]
for (j in ncol(x)) {
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
print(i, j)
x[i, j] = 1
}
}
}
}
x
texts <- str_to_lower(texts)
n <- length(texts)
all_words <- str_split(texts, " ") %>% unlist()
unique_terms <- str_split(texts, " ") %>% unlist() %>% unique()
k <- length(unique_terms)
x <- matrix(nrow = n, ncol = k, 0)
for (i in 1:nrow(x)) {
current_text <- str_split(texts[i], " ")[[1]]
for (j in 1:ncol(x)) {
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
print(i, j)
x[i, j] = 1
}
}
}
}
x
colnames(x, paste0("document", 1:3))
rownames(x, paste0("document", 1:3))
paste0("document", 1:3)
?rownames
rownames(x) <- paste0("document_", 1:3))
rownames(x) <- paste0("document_", 1:3)
colnames(x) <- unique_terms
x
create_dtm <- function(texts) {
texts <- str_to_lower(texts)
n <- length(texts)
all_words <- str_split(texts, " ") %>% unlist()
unique_terms <- str_split(texts, " ") %>% unlist() %>% unique()
k <- length(unique_terms)
x <- matrix(nrow = n, ncol = k, 0)
for (i in 1:nrow(x)) {
current_text <- str_split(texts[i], " ")[[1]]
for (j in 1:ncol(x)) {
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
x[i, j] = x[i, j] + 1
}
}
}
}
rownames(x) <- paste0("document_", 1:3)
colnames(x) <- unique_terms
return(x)
}
texts
create_dtm(texts)
my_dtm <- DocumentTermMatrix(texts)
my_dtm
inspect(dtm)
banana_corpus
banana_corpus[1:3, ]
john_rates
banana_data[1:3, ] %>% colSums()
john_rates
dmultinom(banana_data[8, ], prob = probs_1)
dmultinom(banana_data[7, ], prob = probs_1)
dmultinom(banana_data[8, ], prob = probs_1)
0^1
1^1
1^0
factorial(3) / (factorial(0) * factorial(0) * factorial(2) * factorial(1))
0.58^0 * 0.33^0 * 0.8^2 * 0^1
0.58^2 * 0.33^2 * 0.8^0 * 0^0
first_part <- factorial(4) / (factorial(2) * factorial(2) * factorial(0) * factorial(0))
second_part <- 0.58^2 * 0.33^2 * 0.8^0 * 0^0
first_part * second_part
probs_john ^ unknown_2
vector(NA, length = 10)
v <- c(50,52,45,30,12,52,47,68,72,120,50,20) # creating a vector
mean(v)
sum(v) / length(v)
?read.csv2
knitr::opts_chunk$set(echo = TRUE)
texts <- c("John loves icecream",
"John loves oranges",
"Marry hates icecream")
create_dtm <- function(texts) {
texts <- str_to_lower(texts)
all_words <- str_split(texts, " ") %>% unlist()
unique_terms <- str_split(texts, " ") %>% unlist() %>% unique()
n <- length(texts)
k <- length(unique_terms)
x <- matrix(nrow = n, ncol = k, 0)
for (i in 1:nrow(x)) {
current_text <- str_split(texts[i], " ")[[1]]
for (j in 1:ncol(x)) {
for (y in 1:length(current_text)) {
if (unique_terms[j] %in% current_text[y]) {
x[i, j] = x[i, j] + 1
}
}
}
}
rownames(x) <- paste0("document_", 1:3)
colnames(x) <- unique_terms
return(x)
}
create_dtm(texts)
my_dtm <- DocumentTermMatrix(texts)
my_dtm
rm(list = ls())
Text_1 = "banana  banana banana banana chocolate"
Text_3 = "chocolate chocolate chocolate banana"
Text_2 = "banana banana"
Text_1
texts <- c(Text_1, Text_2, Text_3)
texts
banana_corpus <- c(Text_1, Text_2, Text_3, Text_4, Text_5, Text_6,
Text_7, Text_8)
Text_1 = "banana  banana banana banana chocolate"
Text_2 = "banana banana"
Text_3 = "chocolate chocolate chocolate banana fudge"
Text_4 = "icecream icecream fudge icecream"
Text_5 = "fudge fudge fudge"
Text_6 = "icecream icecream fudge fudge"
Text_7 = "icecream  fudge fudge"
Text_8 = "chocolate chocolate banana banana"
banana_corpus <- c(Text_1, Text_2, Text_3, Text_4, Text_5, Text_6,
Text_7, Text_8)
dtm <- DocumentTermMatrix(banana_corpus)
banana_data <- as.matrix(dtm)
banana_data
fed
fed <- jsonlite::stream_in(file("~/Desktop/tad_course/federalist.json"))
fed <- fed %>% as_tibble()
fed
write_csv("~/Desktop/text-as-data-in-R/federalist.csv")
fed %>% write_csv("~/Desktop/text-as-data-in-R/federalist.csv")
getwd()
setwd("~/Desktop/text-as-data-in-R/")
knitr::opts_chunk$set(echo = TRUE)
clean_federalist$text[1]
knitr::opts_chunk$set(echo = TRUE)
r = getOption("repos")
r["CRAN"] = "http://cran.us.r-project.org"
options(repos = r)
# install.packages("tm")
# install.packages("tidyverse")
# install.packages("ggthemes") # for nicer graphics
library(tm)
library(tidyverse)
library(openNLP)
library(SnowballC)
getwd()
setwd("~/Desktop/text-as-data-in-R/") # this is an example, paste your path here
federalist <- read_csv("federalist.csv")
federalist
names(federalist)
federalist$text[1] # explain this!
clean_federalist <- federalist %>%
mutate(                           # the mutate() function is part of dplyr package / allows to change stuff within the dataframe easily
text   = str_to_lower(text),                # turn all letters to lowercase
text   = str_replace_all(text, "\n", " "),  # replace '/n' carriage return symbols
text   = str_remove_all(text, "[:punct:]"), # remove all punctuation
man    = str_count(text, "\\Wman "),        # Basic regex (more about it later in the course. '\\W' part means at the begging of the word)
by     = str_count(text, "\\Wby "),         # same
upon   = str_count(text, "\\Wupon ")        # same
) %>%
rowwise() %>%                                 # make future functions work rowwise
mutate(
length = length(str_split(text, " ")[[1]])  # calculate the length of the text (in words)
)
clean_federalist <- federalist %>%
mutate(                           # the mutate() function is part of dplyr package / allows to change stuff within the dataframe easily
text   = str_to_lower(text),                # turn all letters to lowercase
text   = str_replace_all(text, "\n", " "),  # replace '/n' carriage return symbols
text   = str_remove_all(text, "[:punct:]"), # remove all punctuation
man    = str_count(text, "\\Wman "),        # Basic regex (more about it later in the course. '\\W' part means at the begging of the word)
by     = str_count(text, "\\Wby "),         # same
upon   = str_count(text, "\\Wupon ")        # same
) %>%
rowwise() %>%                                 # make future functions work rowwise
mutate(
length = length(str_split(text, " ")[[1]])  # calculate the length of the text (in words)
)
clean_federalist$text[1]
clean_federalist$text[1][1:10]
head(clean_federalist$text[1])
clean_federalist
clean_federalist %>%
select(man, by, up)
?dmultinom
install.packages(matlib)
install.packages("matlib")
library(matlib)
library(matlib)
library(matlib)
library(SnowballC)
library(matlib)
library(matlib)
